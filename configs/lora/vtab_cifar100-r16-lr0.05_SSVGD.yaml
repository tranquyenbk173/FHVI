# pytorch_lightning==2.0.2
trainer:
  accelerator: gpu
  devices: 1
  logger:
    class_path: pytorch_lightning.loggers.CSVLogger
    init_args:
      save_dir: output
      name: cifar100-lora-r8-lr-0.15_SSVGD
  max_epochs: 100
  # max_steps: 10000
  val_check_interval: 50
  num_sanity_val_steps: 0
model:
  model_name: vit-b16-224-dino
  training_mode: lora
  optimizer: SWAG
  lr: 0.15
  momentum: 0.9
  weight_decay: 0.0
  scheduler: cosine
  warmup_steps: 500
  lora_r: 8
  lora_alpha: 8
  num_particles: 1
  cov_mat: True
  max_num_models: 20
  use_sam: False
  start_swa_step: 1
  swa_freq: 1
  use_swa_svgd: True 
  use_sym_kl: True
data:
  dataset: cifar100
  root: ../Z.Data/vtab-1k/cifar100/
  size: 224
  batch_size: 24
  workers: 4
model_checkpoint:
  dirpath: saved_checkpoints
  filename: best-step-{step}-{val_acc:.4f}
  monitor: val_acc
  mode: max
  save_last: true
