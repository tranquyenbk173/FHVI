trainer:
  accelerator: gpu
  devices: 1
  logger:
    class_path: pytorch_lightning.loggers.CSVLogger
    init_args:
      save_dir: output
      name: flowers102-lora-r8-lr-0.15_deepEns_4
  max_epochs: 150
  # max_steps: 10000
  val_check_interval: 50
  num_sanity_val_steps: 0
model:
  model_name: vit-b16-224-dino
  training_mode: lora
  optimizer: deep_ens
  lr: 0.15
  momentum: 0.9
  weight_decay: 0.0
  scheduler: cosine
  warmup_steps: 500
  lora_r: 8
  lora_alpha: 8
  num_particles: 4
  epsilon: 0.01
  use_sam: False
data:
  dataset: flowers102
  root: ../vtab-1k/oxford_flowers102
  size: 224
  batch_size: 4
  workers: 4
model_checkpoint:
  dirpath: saved_checkpoints
  filename: best-step-{step}-{val_acc:.4f}
